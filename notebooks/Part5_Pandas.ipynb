{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for R users\n",
    "# Part 5: Data wrangling and analysis using Pandas\n",
    "\n",
    "In this notebook we will explore how to use the Pandas library to work with data.  Pandas has a structure that is conceptually similar to R in some ways, but very different in others. There are some great tutorials on Pandas linked [here](http://www.data-analysis-in-python.org/3_pandas.html).\n",
    "\n",
    "First we need to tell Jupyter to let us use R within this Python notebook, and import some necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "from pprint import pprint\n",
    "\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data types in Pandas\n",
    "\n",
    "There are two main types of data structures in Pandas that we will need to use: Series, and Data Frames.  Let's first introduce Series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series in Pandas\n",
    "\n",
    "A Series is a one-dimensional data structure, akin to a vector.  The main difference between a Pandas Series and a list or vector is that the Series contains some additional indexing information.  To see how this works, let's generate some numbers and put them in a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -0.204708\n",
      "1    0.478943\n",
      "2   -0.519439\n",
      "3   -0.555730\n",
      "4    1.965781\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "numpy.random.seed(12345)  # fix the random seed for reproducibility\n",
    "\n",
    "s = pandas.Series(numpy.random.randn(5))\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index for this Series by default is a series of integers starting at zero.  However, we can also specify an index explicity. Let's say that our 5 numbers come from 5 different people, and we want to use their names as the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lisa     1.393406\n",
      "Sue      0.092908\n",
      "Karen    0.281746\n",
      "Lucy     0.769023\n",
      "Helen    1.246435\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "s_indexed = pandas.Series(numpy.random.randn(5),\n",
    "                  index=['Lisa', 'Sue', 'Karen', 'Lucy', 'Helen'])\n",
    "print(s_indexed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access the index directly using the ```.index``` element of the Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Lisa', 'Sue', 'Karen', 'Lucy', 'Helen'], dtype='object')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_indexed.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can set the index using that element as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lisa    -0.204708\n",
      "Sue      0.478943\n",
      "Karen   -0.519439\n",
      "Lucy    -0.555730\n",
      "Helen    1.965781\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "s.index = ['Lisa', 'Sue', 'Karen', 'Lucy', 'Helen']\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nice feature is that we can then access the data using the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9657805725027142\n",
      "Karen   -0.519439\n",
      "Lucy    -0.555730\n",
      "Helen    1.965781\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# access a single element\n",
    "print(s['Helen'])\n",
    "\n",
    "# access a range of elements\n",
    "print(s['Karen':'Helen'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also index based on the values of the series --- for example, we can find all entries with values less than zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lisa    -0.204708\n",
      "Karen   -0.519439\n",
      "Lucy    -0.555730\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(s[s<0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works because ```s < 0``` returns a Boolean series, and using a Boolean series as a index to another Series will return all of the places where the Boolean series is true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lisa      True\n",
      "Sue      False\n",
      "Karen     True\n",
      "Lucy      True\n",
      "Helen    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(s < 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you may want to extract the values from a Series back into a Numpy array. You can do this using the ```.values``` element of the Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.20470766,  0.47894334, -0.51943872, -0.5557303 ,  1.96578057])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can sort the Series according to the data values using the ```.sort_values()``` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lucy    -0.555730\n",
      "Karen   -0.519439\n",
      "Lisa    -0.204708\n",
      "Sue      0.478943\n",
      "Helen    1.965781\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "s_sorted = s.sort_values()\n",
    "print(s_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's say that you wanted to only take the top three of the sorted list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lisa    -0.204708\n",
       "Sue      0.478943\n",
       "Helen    1.965781\n",
       "dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_sorted[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data frames\n",
    "\n",
    "The concept of a data frame will be very familiar to R users, and the Pandas library provides a very similar functionality for Python.  We will spend a good bit of time on data frames because of their importance.  We will move to working with real data shortly, but we will start with a simple example.  First let's create a data frame in R with two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  x  y\n",
       "1 1  5\n",
       "2 2  7\n",
       "3 3  9\n",
       "4 4 11\n",
       "5 5 13\n",
       "   y\n",
       "1  5\n",
       "2  7\n",
       "3  9\n",
       "4 11\n",
       "5 13\n",
       "       x           y     \n",
       " Min.   :1   Min.   : 5  \n",
       " 1st Qu.:2   1st Qu.: 7  \n",
       " Median :3   Median : 9  \n",
       " Mean   :3   Mean   : 9  \n",
       " 3rd Qu.:4   3rd Qu.:11  \n",
       " Max.   :5   Max.   :13  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "x <- c(1, 2, 3, 4, 5)\n",
    "y <- x * 2 + 3\n",
    "\n",
    "df <- data.frame(x = x, y = y)\n",
    "print(df)\n",
    "\n",
    "# access one of the variables in the data frame\n",
    "print(df['y'])\n",
    "\n",
    "# summarize the variables in the data frame\n",
    "summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create an analogous data frame in Python.  There are various ways to get data into a data frame - in this case we will specify them as a dictionary to the ```pandas.DataFrame()``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x   y\n",
      "0  1   5\n",
      "1  2   7\n",
      "2  3   9\n",
      "3  4  11\n",
      "4  5  13\n",
      "0     5\n",
      "1     7\n",
      "2     9\n",
      "3    11\n",
      "4    13\n",
      "Name: y, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.581139</td>\n",
       "      <td>3.162278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              x          y\n",
       "count  5.000000   5.000000\n",
       "mean   3.000000   9.000000\n",
       "std    1.581139   3.162278\n",
       "min    1.000000   5.000000\n",
       "25%    2.000000   7.000000\n",
       "50%    3.000000   9.000000\n",
       "75%    4.000000  11.000000\n",
       "max    5.000000  13.000000"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = numpy.array([1, 2, 3, 4, 5])\n",
    "y = x * 2 + 3\n",
    "\n",
    "df = pandas.DataFrame({'x': x, 'y': y})\n",
    "print(df)\n",
    "\n",
    "# access one of the variables in the data frame\n",
    "# note that this becomes a pandas Series\n",
    "print(df.y)\n",
    "\n",
    "# summarize the variables in the data frame\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing columns\n",
    "\n",
    "There are several different ways to access specific elements of a Pandas data frame.  First, let's look at accessing the columns. There are two ways to access a column by name. You have already seen one above, using the dot notation.  A column can also be accessed by putting its name in brackets, as in R:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     5\n",
      "1     7\n",
      "2     9\n",
      "3    11\n",
      "4    13\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns can also be accessed based on their numeric position, using the standard indexing that saw for Numpy arrays.  This is done using the ```.iloc``` operator to the data frame.  The first dimension in the iloc argument refers to the row, and the second to the column.  Thus, if we wanted to access the first three elements in the second columns, we would use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    7\n",
       "2    9\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:3, 1]  # columns are indexed from zero, so 1 refers to the second column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing rows\n",
    "\n",
    "There are two different ways to access a row in a Pandas data frame. \n",
    "\n",
    "The first you have already seen in the previous section, using the ```.iloc``` operator to index them numerically based on their position in the array.  \n",
    "\n",
    "The second relies upon the data frame's index, using the ```.loc``` operator.  Let's say that we want to extract the third row, which in this case has an index value of 2.  We could do that as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x    3\n",
      "y    9\n",
      "Name: 2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we would like a more descriptive index.  For example, let's say that our five rows refer to five different cities in California.  We can set the index using the ```index``` operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               x   y\n",
      "Los Angeles    1   5\n",
      "Santa Barbara  2   7\n",
      "Sacramento     3   9\n",
      "Bakersfield    4  11\n",
      "San Francisco  5  13\n"
     ]
    }
   ],
   "source": [
    "df.index = ['Los Angeles', 'Santa Barbara', 'Sacramento', 'Bakersfield', 'San Francisco']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we want to access the data for Sacremento, we can do that using the ```.loc``` operator:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x    3\n",
       "y    9\n",
       "Name: Sacramento, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['Sacramento']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and working with data\n",
    "\n",
    "Pandas is the tool that one would most often use to load and work with data sets.  As an example, let's read a real dataset from disk and show how we would work with it using Pandas.\n",
    "\n",
    "We will use a real dataset from [Eisenberg et al, 2019](nature.com/articles/s41467-019-10301-1), which contains data for 522 individuals on 192 variables derived from a set of psychological tasks.  Let's say that we want to know whether the stop signal reaction time (SSRT - measured across several different tasks) is related to self-reported impulsivity (as measured using a number of different surveys).  \n",
    "\n",
    "First we load the data.  The subject codes are contained in the first column, and we tell pandas to use those codes as the index for the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adaptive_n_back.hddm_drift</th>\n",
       "      <th>adaptive_n_back.hddm_drift_load</th>\n",
       "      <th>adaptive_n_back.hddm_non_decision</th>\n",
       "      <th>adaptive_n_back.hddm_thresh</th>\n",
       "      <th>adaptive_n_back.mean_load.logTr</th>\n",
       "      <th>angling_risk_task_always_sunny.keep_adjusted_clicks</th>\n",
       "      <th>angling_risk_task_always_sunny.keep_coef_of_variation</th>\n",
       "      <th>angling_risk_task_always_sunny.release_adjusted_clicks</th>\n",
       "      <th>angling_risk_task_always_sunny.release_coef_of_variation.logTr</th>\n",
       "      <th>attention_network_task.alerting_hddm_drift</th>\n",
       "      <th>...</th>\n",
       "      <th>two_stage_decision.model_based</th>\n",
       "      <th>two_stage_decision.model_free</th>\n",
       "      <th>two_stage_decision.perseverance</th>\n",
       "      <th>upps_impulsivity_survey.lack_of_perseverance</th>\n",
       "      <th>upps_impulsivity_survey.lack_of_premeditation</th>\n",
       "      <th>upps_impulsivity_survey.negative_urgency</th>\n",
       "      <th>upps_impulsivity_survey.positive_urgency</th>\n",
       "      <th>upps_impulsivity_survey.sensation_seeking</th>\n",
       "      <th>writing_task.neutral_probability</th>\n",
       "      <th>writing_task.positive_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.250000</td>\n",
       "      <td>8.051643</td>\n",
       "      <td>17.090909</td>\n",
       "      <td>2.199145</td>\n",
       "      <td>-0.558765</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>0.201794</td>\n",
       "      <td>0.189649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s002</th>\n",
       "      <td>1.187554</td>\n",
       "      <td>-0.410072</td>\n",
       "      <td>0.090573</td>\n",
       "      <td>1.863749</td>\n",
       "      <td>0.182322</td>\n",
       "      <td>20.260870</td>\n",
       "      <td>17.184077</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.978096</td>\n",
       "      <td>-0.189757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.393831</td>\n",
       "      <td>-0.122940</td>\n",
       "      <td>-0.895623</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.090909</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>0.817275</td>\n",
       "      <td>0.192216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s003</th>\n",
       "      <td>2.215680</td>\n",
       "      <td>-0.726543</td>\n",
       "      <td>0.025634</td>\n",
       "      <td>2.150399</td>\n",
       "      <td>0.371564</td>\n",
       "      <td>13.080000</td>\n",
       "      <td>5.992495</td>\n",
       "      <td>10.086957</td>\n",
       "      <td>1.833585</td>\n",
       "      <td>-0.430268</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.363636</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.785714</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0.412338</td>\n",
       "      <td>0.231957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s004</th>\n",
       "      <td>2.065906</td>\n",
       "      <td>-0.507549</td>\n",
       "      <td>0.037627</td>\n",
       "      <td>2.385402</td>\n",
       "      <td>0.854415</td>\n",
       "      <td>13.464286</td>\n",
       "      <td>2.937398</td>\n",
       "      <td>8.928571</td>\n",
       "      <td>1.181606</td>\n",
       "      <td>-0.485213</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.417454</td>\n",
       "      <td>-0.083370</td>\n",
       "      <td>-0.591512</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.636364</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>0.888122</td>\n",
       "      <td>0.256883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s005</th>\n",
       "      <td>3.221946</td>\n",
       "      <td>-1.235354</td>\n",
       "      <td>0.285800</td>\n",
       "      <td>1.580276</td>\n",
       "      <td>0.500775</td>\n",
       "      <td>36.363636</td>\n",
       "      <td>13.145868</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>2.453175</td>\n",
       "      <td>-0.238605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.665538</td>\n",
       "      <td>0.103557</td>\n",
       "      <td>1.355168</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>0.886852</td>\n",
       "      <td>0.405901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      adaptive_n_back.hddm_drift  adaptive_n_back.hddm_drift_load  \\\n",
       "s001                         NaN                              NaN   \n",
       "s002                    1.187554                        -0.410072   \n",
       "s003                    2.215680                        -0.726543   \n",
       "s004                    2.065906                        -0.507549   \n",
       "s005                    3.221946                        -1.235354   \n",
       "\n",
       "      adaptive_n_back.hddm_non_decision  adaptive_n_back.hddm_thresh  \\\n",
       "s001                                NaN                          NaN   \n",
       "s002                           0.090573                     1.863749   \n",
       "s003                           0.025634                     2.150399   \n",
       "s004                           0.037627                     2.385402   \n",
       "s005                           0.285800                     1.580276   \n",
       "\n",
       "      adaptive_n_back.mean_load.logTr  \\\n",
       "s001                              NaN   \n",
       "s002                         0.182322   \n",
       "s003                         0.371564   \n",
       "s004                         0.854415   \n",
       "s005                         0.500775   \n",
       "\n",
       "      angling_risk_task_always_sunny.keep_adjusted_clicks  \\\n",
       "s001                                          24.250000     \n",
       "s002                                          20.260870     \n",
       "s003                                          13.080000     \n",
       "s004                                          13.464286     \n",
       "s005                                          36.363636     \n",
       "\n",
       "      angling_risk_task_always_sunny.keep_coef_of_variation  \\\n",
       "s001                                           8.051643       \n",
       "s002                                          17.184077       \n",
       "s003                                           5.992495       \n",
       "s004                                           2.937398       \n",
       "s005                                          13.145868       \n",
       "\n",
       "      angling_risk_task_always_sunny.release_adjusted_clicks  \\\n",
       "s001                                          17.090909        \n",
       "s002                                          13.000000        \n",
       "s003                                          10.086957        \n",
       "s004                                           8.928571        \n",
       "s005                                          30.500000        \n",
       "\n",
       "      angling_risk_task_always_sunny.release_coef_of_variation.logTr  \\\n",
       "s001                                           2.199145                \n",
       "s002                                           1.978096                \n",
       "s003                                           1.833585                \n",
       "s004                                           1.181606                \n",
       "s005                                           2.453175                \n",
       "\n",
       "      attention_network_task.alerting_hddm_drift  \\\n",
       "s001                                   -0.558765   \n",
       "s002                                   -0.189757   \n",
       "s003                                   -0.430268   \n",
       "s004                                   -0.485213   \n",
       "s005                                   -0.238605   \n",
       "\n",
       "                    ...                  two_stage_decision.model_based  \\\n",
       "s001                ...                                             NaN   \n",
       "s002                ...                                       -0.393831   \n",
       "s003                ...                                             NaN   \n",
       "s004                ...                                       -0.417454   \n",
       "s005                ...                                        0.665538   \n",
       "\n",
       "      two_stage_decision.model_free  two_stage_decision.perseverance  \\\n",
       "s001                            NaN                              NaN   \n",
       "s002                      -0.122940                        -0.895623   \n",
       "s003                            NaN                              NaN   \n",
       "s004                      -0.083370                        -0.591512   \n",
       "s005                       0.103557                         1.355168   \n",
       "\n",
       "      upps_impulsivity_survey.lack_of_perseverance  \\\n",
       "s001                                           1.5   \n",
       "s002                                           1.5   \n",
       "s003                                           2.4   \n",
       "s004                                           1.5   \n",
       "s005                                           1.7   \n",
       "\n",
       "      upps_impulsivity_survey.lack_of_premeditation  \\\n",
       "s001                                       1.909091   \n",
       "s002                                       2.090909   \n",
       "s003                                       2.363636   \n",
       "s004                                       1.636364   \n",
       "s005                                       1.363636   \n",
       "\n",
       "      upps_impulsivity_survey.negative_urgency  \\\n",
       "s001                                  1.583333   \n",
       "s002                                  3.000000   \n",
       "s003                                  3.000000   \n",
       "s004                                  1.583333   \n",
       "s005                                  1.750000   \n",
       "\n",
       "      upps_impulsivity_survey.positive_urgency  \\\n",
       "s001                                  2.142857   \n",
       "s002                                  3.285714   \n",
       "s003                                  2.785714   \n",
       "s004                                  1.142857   \n",
       "s005                                  1.000000   \n",
       "\n",
       "      upps_impulsivity_survey.sensation_seeking  \\\n",
       "s001                                   3.416667   \n",
       "s002                                   3.083333   \n",
       "s003                                   2.833333   \n",
       "s004                                   1.916667   \n",
       "s005                                   2.833333   \n",
       "\n",
       "      writing_task.neutral_probability  writing_task.positive_probability  \n",
       "s001                          0.201794                           0.189649  \n",
       "s002                          0.817275                           0.192216  \n",
       "s003                          0.412338                           0.231957  \n",
       "s004                          0.888122                           0.256883  \n",
       "s005                          0.886852                           0.405901  \n",
       "\n",
       "[5 rows x 193 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.read_csv('meaningful_variables_clean.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to select the variables that we will use for the analysis. First, let's find the SSRT variables.  To do this, we will loop through all of the variable names and find the ones that include \"ssrt\".  In R we would access the column names using ```names()``` whereas in Python we access them using the ```.columns``` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['adaptive_n_back.hddm_drift', 'adaptive_n_back.hddm_drift_load',\n",
       "       'adaptive_n_back.hddm_non_decision', 'adaptive_n_back.hddm_thresh',\n",
       "       'adaptive_n_back.mean_load.logTr',\n",
       "       'angling_risk_task_always_sunny.keep_adjusted_clicks',\n",
       "       'angling_risk_task_always_sunny.keep_coef_of_variation',\n",
       "       'angling_risk_task_always_sunny.release_adjusted_clicks',\n",
       "       'angling_risk_task_always_sunny.release_coef_of_variation.logTr',\n",
       "       'attention_network_task.alerting_hddm_drift',\n",
       "       ...\n",
       "       'two_stage_decision.model_based', 'two_stage_decision.model_free',\n",
       "       'two_stage_decision.perseverance',\n",
       "       'upps_impulsivity_survey.lack_of_perseverance',\n",
       "       'upps_impulsivity_survey.lack_of_premeditation',\n",
       "       'upps_impulsivity_survey.negative_urgency',\n",
       "       'upps_impulsivity_survey.positive_urgency',\n",
       "       'upps_impulsivity_survey.sensation_seeking',\n",
       "       'writing_task.neutral_probability',\n",
       "       'writing_task.positive_probability'],\n",
       "      dtype='object', length=193)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's loop through all of the column names and save the ones that have 'ssrt' in their name.  We will learn more about processing strings in a later section; here we will introduce the ```.find()``` operator that is present for strings.  This operator tells us the location of a particular string within another string, or returns -1 if the string is not present.  For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "a = 'This is a string'\n",
    "print(a.find('is'))\n",
    "print(a.find('number'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how we would do it for the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['motor_selective_stop_signal.SSRT', 'stim_selective_stop_signal.SSRT', 'stop_signal.SSRT_high.logTr', 'stop_signal.SSRT_low']\n",
      "['bis11_survey.Attentional', 'bis11_survey.Motor.logTr', 'bis11_survey.Nonplanning']\n"
     ]
    }
   ],
   "source": [
    "# first find SSRT variables\n",
    "\n",
    "ssrt_variables = []  # empty list to save names\n",
    "for c in data.columns:\n",
    "    if c.find('.SSRT') > -1:\n",
    "        ssrt_variables.append(c)\n",
    "        \n",
    "print(ssrt_variables)\n",
    "\n",
    "# find BIS-11\n",
    "\n",
    "bis11_variables = []  # empty list to save names\n",
    "for c in data.columns:\n",
    "    if c.find('bis11') > -1:\n",
    "        bis11_variables.append(c)\n",
    "        \n",
    "print(bis11_variables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have found the variables of interest for SSRT and BIS-11.  However, you can see above that we have repeated the same code in two places, which is bad form.  What we should do instead is find a way to loop through the variables we are interested in, so that if we decide that we want to add more then we can do that easily later.  First, we should set up a dictionary that contains all of the search strings for each data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SSRT': '.SSRT', 'BIS-11': 'bis11', 'UPPS-P': 'upps', 'Dickman': 'dickman'}\n"
     ]
    }
   ],
   "source": [
    "search_strings = {\n",
    "    'SSRT': '.SSRT',\n",
    "    'BIS-11': 'bis11',\n",
    "    'UPPS-P': 'upps',\n",
    "    'Dickman': 'dickman'\n",
    "}\n",
    "print(search_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's adapt the code above to loop through the different variables.  Tip: Putting a dictionary as the sequence in a for loop causes it to loop over all of the keys in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BIS-11': ['bis11_survey.Attentional',\n",
      "            'bis11_survey.Motor.logTr',\n",
      "            'bis11_survey.Nonplanning'],\n",
      " 'Dickman': ['dickman_survey.functional'],\n",
      " 'SSRT': ['motor_selective_stop_signal.SSRT',\n",
      "          'stim_selective_stop_signal.SSRT',\n",
      "          'stop_signal.SSRT_high.logTr',\n",
      "          'stop_signal.SSRT_low'],\n",
      " 'UPPS-P': ['upps_impulsivity_survey.lack_of_perseverance',\n",
      "            'upps_impulsivity_survey.lack_of_premeditation',\n",
      "            'upps_impulsivity_survey.negative_urgency',\n",
      "            'upps_impulsivity_survey.positive_urgency',\n",
      "            'upps_impulsivity_survey.sensation_seeking']}\n"
     ]
    }
   ],
   "source": [
    "variable_names = {}\n",
    "for ss in search_strings:\n",
    "    variable_names[ss] = []  # create empty list to store matching names for this string\n",
    "    for c in data.columns:\n",
    "        if c.find(search_strings[ss]) > -1:\n",
    "            variable_names[ss].append(c)\n",
    "\n",
    "pprint(variable_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have found all of the relevant variables, let's create a new data frame that only includes those variables.  First we will create a list with all of the matching variables, and then filter the data frame for these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['motor_selective_stop_signal.SSRT', 'stim_selective_stop_signal.SSRT',\n",
       "       'stop_signal.SSRT_high.logTr', 'stop_signal.SSRT_low',\n",
       "       'bis11_survey.Attentional', 'bis11_survey.Motor.logTr',\n",
       "       'bis11_survey.Nonplanning',\n",
       "       'upps_impulsivity_survey.lack_of_perseverance',\n",
       "       'upps_impulsivity_survey.lack_of_premeditation',\n",
       "       'upps_impulsivity_survey.negative_urgency',\n",
       "       'upps_impulsivity_survey.positive_urgency',\n",
       "       'upps_impulsivity_survey.sensation_seeking',\n",
       "       'dickman_survey.functional'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables_to_keep = []\n",
    "for v in variable_names:\n",
    "    variables_to_keep += variable_names[v]\n",
    "\n",
    "data_selected = data[variables_to_keep]\n",
    "data_selected.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's clean up the data by removing all of the missing data, using the ```.dropna()``` operator.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 13)\n"
     ]
    }
   ],
   "source": [
    "data_selected = data_selected.dropna()\n",
    "print(data_selected.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to compute the average of all SSRT variables and the average of all of the impulsivity variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_selected['mean_SSRT'] = data_selected[variable_names['SSRT']].mean(axis=1)\n",
    "\n",
    "# create a list containing all of the variables except those for SSRT\n",
    "# using set operations\n",
    "\n",
    "impulsivity_variables = set(variables_to_keep).difference(variable_names['SSRT'])\n",
    "\n",
    "# we need to turn the set back into a list so it can be used as an index\n",
    "data_selected['mean_impulsivity'] = data_selected[list(impulsivity_variables)].mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the correlation between those two mean variables of interest, using the built-in correlation method ```.corr()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_impulsivity</th>\n",
       "      <th>mean_SSRT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_impulsivity</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.043986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_SSRT</th>\n",
       "      <td>-0.043986</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  mean_impulsivity  mean_SSRT\n",
       "mean_impulsivity          1.000000  -0.043986\n",
       "mean_SSRT                -0.043986   1.000000"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_selected[['mean_impulsivity', 'mean_SSRT']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining datasets\n",
    "\n",
    "Often we will want to combine data that are stored in multiple files.  Just like R, pandas provides tools for merging datasets using a common set of indices, using the ```.merge()``` operator.  Let's say that we want to combine our data above with some demographic data, so that we can ask whether impulsivity and SSRT are related to ever having been arrested in one's life.  These data are stored in a separate file (demographics.csv).  First we load the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Race</th>\n",
       "      <th>OtherRace</th>\n",
       "      <th>HispanicLatino</th>\n",
       "      <th>HighestEducation</th>\n",
       "      <th>HeightInches</th>\n",
       "      <th>WeightPounds</th>\n",
       "      <th>RelationshipStatus</th>\n",
       "      <th>DivorceCount</th>\n",
       "      <th>...</th>\n",
       "      <th>CoffeeCupsPerDay</th>\n",
       "      <th>TeaCupsPerDay</th>\n",
       "      <th>CaffienatedSodaCansPerDay</th>\n",
       "      <th>CaffieneOtherSourcesDayMG</th>\n",
       "      <th>GamblingProblem</th>\n",
       "      <th>TrafficTicketsLastYearCount</th>\n",
       "      <th>TrafficAccidentsLifeCount</th>\n",
       "      <th>ArrestedChargedLifeCount</th>\n",
       "      <th>MotivationForParticipation</th>\n",
       "      <th>MotivationOther</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s001</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>money</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s002</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>money</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s003</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>73</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>money</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s004</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>money</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s005</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>76</td>\n",
       "      <td>175</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>money</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Age                        Race OtherRace  HispanicLatino  \\\n",
       "s001    1   27                       White       NaN               1   \n",
       "s002    0   35                       White       NaN               0   \n",
       "s003    0   25                       White       NaN               0   \n",
       "s004    0   35                       White       NaN               0   \n",
       "s005    0   36   Black or African American       NaN               0   \n",
       "\n",
       "      HighestEducation  HeightInches  WeightPounds  RelationshipStatus  \\\n",
       "s001                 3            62           110                   2   \n",
       "s002                 2            72           240                   2   \n",
       "s003                 4            73           185                   1   \n",
       "s004                 4            71           190                   1   \n",
       "s005                 3            76           175                   1   \n",
       "\n",
       "      DivorceCount       ...         CoffeeCupsPerDay  TeaCupsPerDay  \\\n",
       "s001             0       ...                      1.0            0.0   \n",
       "s002             0       ...                      3.0            0.0   \n",
       "s003             0       ...                      1.0            0.0   \n",
       "s004             0       ...                      0.0            0.0   \n",
       "s005             0       ...                      0.0            0.0   \n",
       "\n",
       "      CaffienatedSodaCansPerDay  CaffieneOtherSourcesDayMG  GamblingProblem  \\\n",
       "s001                        0.0                        0.0              0.0   \n",
       "s002                        0.0                        0.0              0.0   \n",
       "s003                        0.0                       90.0              0.0   \n",
       "s004                        0.0                        0.0              0.0   \n",
       "s005                        0.0                        0.0              1.0   \n",
       "\n",
       "      TrafficTicketsLastYearCount  TrafficAccidentsLifeCount  \\\n",
       "s001                          0.0                        1.0   \n",
       "s002                          0.0                        3.0   \n",
       "s003                          0.0                        1.0   \n",
       "s004                          0.0                        0.0   \n",
       "s005                          0.0                        3.0   \n",
       "\n",
       "      ArrestedChargedLifeCount  MotivationForParticipation  MotivationOther  \n",
       "s001                       0.0                       money              NaN  \n",
       "s002                       0.0                       money              NaN  \n",
       "s003                       0.0                       money              NaN  \n",
       "s004                       0.0                       money              NaN  \n",
       "s005                       5.0                       money              NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demogdata = pandas.read_csv('demographics.csv', index_col=0)\n",
    "demogdata.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a variable called \"ArrestedChargedLifeCount\" that contains the self-reported number of times that a person has been arrested in their life.  Let's create a new variable that is True if the person has ever been arrested:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "demogdata['EverArrested'] = demogdata.ArrestedChargedLifeCount > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: When you are referring to the value of a variable within a data frame, you can use either ```dataframe.VariableName``` or ```dataframe['VariableName']```.  However, when you are adding a new variable to a data frame, you must use the latter syntax.\n",
    "\n",
    "Now let's join the new variable with the data from above.  We want to only include cases that are present in both datasets, so we use what is called an \"inner join\" (see [the pandas.DataFrame.join help](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html) for more on this).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_impulsivity</th>\n",
       "      <th>mean_SSRT</th>\n",
       "      <th>EverArrested</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s004</th>\n",
       "      <td>1.911021</td>\n",
       "      <td>200.211691</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s005</th>\n",
       "      <td>2.088186</td>\n",
       "      <td>271.213365</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s009</th>\n",
       "      <td>2.961991</td>\n",
       "      <td>159.057108</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s011</th>\n",
       "      <td>2.060847</td>\n",
       "      <td>176.495160</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s012</th>\n",
       "      <td>2.275128</td>\n",
       "      <td>237.863131</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_impulsivity   mean_SSRT  EverArrested\n",
       "s004          1.911021  200.211691         False\n",
       "s005          2.088186  271.213365          True\n",
       "s009          2.961991  159.057108         False\n",
       "s011          2.060847  176.495160         False\n",
       "s012          2.275128  237.863131         False"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_selected_with_arrest = data_selected[['mean_impulsivity', 'mean_SSRT']].join(demogdata['EverArrested'], how = 'inner')\n",
    "data_selected_with_arrest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping variables using groupby()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to summarize the data by the different groups: Arrested vs. never arrested. Here we can use a method called ```.groupby()``` which is similar to the ```group_by()``` function in dplyr.  First let's group the data and compute the mean for each group on each variable, and then compute normal confidence intervals for each mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              mean_impulsivity   mean_SSRT\n",
      "EverArrested                              \n",
      "False                 2.179763  230.255239\n",
      "True                  2.351907  226.701396\n",
      "              mean_impulsivity  mean_SSRT\n",
      "EverArrested                             \n",
      "False                 0.021448   1.989571\n",
      "True                  0.023668   2.073708\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_SSRT</th>\n",
       "      <th>mean_SSRT_lowerCI</th>\n",
       "      <th>mean_SSRT_upperCI</th>\n",
       "      <th>mean_impulsivity</th>\n",
       "      <th>mean_impulsivity_lowerCI</th>\n",
       "      <th>mean_impulsivity_upperCI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EverArrested</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>230.255239</td>\n",
       "      <td>226.355680</td>\n",
       "      <td>234.154798</td>\n",
       "      <td>2.179763</td>\n",
       "      <td>2.137725</td>\n",
       "      <td>2.221802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>226.701396</td>\n",
       "      <td>222.636929</td>\n",
       "      <td>230.765863</td>\n",
       "      <td>2.351907</td>\n",
       "      <td>2.305518</td>\n",
       "      <td>2.398296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean_SSRT  mean_SSRT_lowerCI  mean_SSRT_upperCI  \\\n",
       "EverArrested                                                     \n",
       "False         230.255239         226.355680         234.154798   \n",
       "True          226.701396         222.636929         230.765863   \n",
       "\n",
       "              mean_impulsivity  mean_impulsivity_lowerCI  \\\n",
       "EverArrested                                               \n",
       "False                 2.179763                  2.137725   \n",
       "True                  2.351907                  2.305518   \n",
       "\n",
       "              mean_impulsivity_upperCI  \n",
       "EverArrested                            \n",
       "False                         2.221802  \n",
       "True                          2.398296  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute means for each group/variable\n",
    "mean_by_group = data_selected_with_arrest.groupby('EverArrested').mean()\n",
    "print(mean_by_group)\n",
    "\n",
    "# comnpute standard errors\n",
    "stderr_by_group = data_selected_with_arrest.groupby('EverArrested').std()/numpy.sqrt(data_selected_with_arrest.shape[0])\n",
    "print(stderr_by_group)\n",
    "\n",
    "# compute normal confidence intervals\n",
    "upper_ci = mean_by_group + stderr_by_group*1.96\n",
    "upper_ci.columns = [i + '_upperCI' for i in upper_ci.columns] # fix names\n",
    "\n",
    "lower_ci = mean_by_group - stderr_by_group*1.96\n",
    "lower_ci.columns = [i + '_lowerCI' for i in lower_ci.columns] # fix names\n",
    "\n",
    "# add back into a single data frame\n",
    "results = pandas.concat([mean_by_group, upper_ci, lower_ci], axis=1) #, ))\n",
    "# reorder the columns\n",
    "result_columns = results.columns.tolist()\n",
    "result_columns.sort()\n",
    "results = results[result_columns]\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eyeballing these results, it appears that there is a difference in impulsivity between the groups.  We will return to this later when we move on to statistical inference.  Before we leave, let's save the data to a csv file so that we can read it back in when we return to this later.  This is easy using the ```.to_csv()``` method with the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_selected_with_arrest.to_csv('arrest_ssrt_impulsivity.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving between wide and long data formats\n",
    "\n",
    "It's common in data analysis to need to move between wide and long data formats.  Here we will work with item-level responses from a set of surveys obtained from the UH2 project, which are stored in subjects_x_items.csv. The items are stored in a wide format, with the item numbers appended to the name of the survey (e.g. eating_survey.02, ... eating_survey.19).  Let's load the data from the eating survey and move the data from wide to long format, first in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[90m# A tibble: 6 x 3\u001b[39m\n",
       "  subjectID item             response\n",
       "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m     \u001b[3m\u001b[90m<fct>\u001b[39m\u001b[23m            \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m   \n",
       "\u001b[90m1\u001b[39m 1         eating_survey.02 3       \n",
       "\u001b[90m2\u001b[39m 2         eating_survey.02 3       \n",
       "\u001b[90m3\u001b[39m 3         eating_survey.02 1       \n",
       "\u001b[90m4\u001b[39m 4         eating_survey.02 2       \n",
       "\u001b[90m5\u001b[39m 5         eating_survey.02 2       \n",
       "\u001b[90m6\u001b[39m 6         eating_survey.02 1       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "library(readr)\n",
    "library(dplyr)\n",
    "library(tidyr)\n",
    "\n",
    "eating_data = read_csv('subject_x_items.csv') %>%\n",
    "    select(c(starts_with(\"eating_survey\"), 'worker')) %>% # select only eating survey items \n",
    "    tibble::rownames_to_column('subjectID')\n",
    "\n",
    "# convert to long format\n",
    "eating_data_long <- gather(eating_data, item, response, -subjectID, factor_key=TRUE)\n",
    "head(eating_data_long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjectID</th>\n",
       "      <th>item</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s001</td>\n",
       "      <td>eating_survey.02</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s002</td>\n",
       "      <td>eating_survey.02</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s003</td>\n",
       "      <td>eating_survey.02</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s004</td>\n",
       "      <td>eating_survey.02</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s005</td>\n",
       "      <td>eating_survey.02</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subjectID              item  response\n",
       "0      s001  eating_survey.02       3.0\n",
       "1      s002  eating_survey.02       3.0\n",
       "2      s003  eating_survey.02       1.0\n",
       "3      s004  eating_survey.02       2.0\n",
       "4      s005  eating_survey.02       2.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eating_data = pandas.read_csv('subject_x_items.csv', index_col=0)\n",
    "keep_cols = [i for i in eating_data.columns if i.find('eating_survey')==0]\n",
    "eating_data = eating_data[keep_cols]\n",
    "eating_data['subjectID'] = eating_data.index\n",
    "\n",
    "eating_data_long = pandas.melt(eating_data,\n",
    "                               id_vars=['subjectID'],\n",
    "                               var_name='item',\n",
    "                               value_name='response')\n",
    "eating_data_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
